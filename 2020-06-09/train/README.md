# Training with MMDetection

Allows processing of images with [MMDetection](https://github.com/open-mmlab/mmdetection).

Uses PyTorch 1.3 and CUDA 10.1.

Does not work on 1080 Ti cards. 

## Version

MMDetection github repo tag/hash:

```
v2.1.0
99a31d25b4d685da5ae868776a0483b80e8fb903
```

and timestamp:

```
June 9th, 2020
```

## Docker

### Build local image

* Build the image from Docker file (from within /path_to/mmdetection/2020-06-09/train)

  ```commandline
  sudo docker build -t mmdet_train .
  ```
  
* Run the container

  ```commandline
  sudo docker run --runtime=nvidia --shm-size 8G -v /local:/container -it \
    -e MMDET_CLASSES=\'class1\',\'class2\',... mmdet_train /path_to/your_data_config.py --autoscale-lr
  ```
  `/local:/container` maps a local disk directory into a directory inside the container


### Pre-built images

* Build

  ```commandline
  docker build -t open-mmlab/mmdetection_train:2020-06-09 .
  ```
  
* Tag

  ```commandline
  docker tag \
    open-mmlab/mmdetection_train:2020-06-09 \
    public-push.aml-repo.cms.waikato.ac.nz:443/open-mmlab/mmdetection_train:2020-06-09
  ```
  
* Push

  ```commandline
  docker push public-push.aml-repo.cms.waikato.ac.nz:443/open-mmlab/mmdetection_train:2020-06-09
  ```
  If error "no basic auth credentials" occurs, then run (enter username/password when prompted):
  
  ```commandline
  docker login public-push.aml-repo.cms.waikato.ac.nz:443
  ```
  
* Pull

  If image is available in aml-repo and you just want to use it, you can pull using following command and then [run](#run).

  ```commandline
  docker pull public.aml-repo.cms.waikato.ac.nz:443/open-mmlab/mmdetection_train:2020-06-09
  ```
  If error "no basic auth credentials" occurs, then run (enter username/password when prompted):
  
  ```commandline
  docker login public.aml-repo.cms.waikato.ac.nz:443
  ```
  Then tag by running:
  
  ```commandline
  docker tag \
    public.aml-repo.cms.waikato.ac.nz:443/open-mmlab/mmdetection_train:2020-06-09 \
    open-mmlab/mmdetection_train:2020-06-09
  ```

* <a name="run">Run</a>

  ```commandline
  docker run --runtime=nvidia --shm-size 8G -v /local:/container -it \
    -e MMDET_CLASSES=\'class1\',\'class2\',... open-mmlab/mmdetection_train:2020-06-09 \
    /path_to/your_data_config.py --autoscale-lr
  ```
  `/local:/container` maps a local disk directory into a directory inside the container


## Permissions

When running the docker container as regular use, you will want to set the correct
user and group on the files generated by the container (aka the user:group launching
the container):

```commandline
docker run -u $(id -u):$(id -g) -e USER=$USER ...
```

## Caching models

PyTorch downloads base models, if necessary. However, by using Docker, this means that 
models will get downloaded with each Docker image, using up unnecessary bandwidth and
slowing down the startup. To avoid this, you can map a directory on the host machine
to cache the base models for all processes (usually, there would be only one concurrent
model being trained):  

```
-v /somewhere/local/cache:/.cache
```

Or specifically for PyTorch:

```
-v /somewhere/local/cache/torch:/.cache/torch
```
